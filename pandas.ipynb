{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4382f781-fcd6-467f-9ba5-27b0cfd03bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of dataframe: \n",
      "   1|24|M|technician|85711\n",
      "0       2|53|F|other|94043\n",
      "1      3|23|M|writer|32067\n",
      "2  4|24|M|technician|43537\n",
      "3       5|33|F|other|15213\n",
      "4   6|42|M|executive|98101\n",
      "Shape: (942, 1)\n",
      "\n",
      "Dataframe after modifying the default parameter values for read_table: \n",
      "   user_id  age gender  occupation zip_code\n",
      "0        1   24      M  technician    85711\n",
      "1        2   53      F       other    94043\n",
      "2        3   23      M      writer    32067\n",
      "3        4   24      M  technician    43537\n",
      "4        5   33      F       other    15213\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "orders = pd.read_table('http://bit.ly/movieusers')\n",
    "print(\"Overview of dataframe: \")\n",
    "print(orders.head())\n",
    "print(\"Shape:\",orders.shape)\n",
    "print()\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('http://bit.ly/movieusers', sep=\"|\", header=None,\n",
    "names=user_cols)\n",
    "print(\"Dataframe after modifying the default parameter values for read_table: \")\n",
    "print(users.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f40a10c-c427-4544-854d-9e64339f4940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of UFO data reports: \n",
      "                   City Colors Reported Shape Reported State             Time\n",
      "0                Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1           Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2               Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "3               Abilene             NaN           DISK    KS   6/1/1931 13:00\n",
      "4  New York Worlds Fair             NaN          LIGHT    NY  4/18/1933 19:00\n",
      "\n",
      "City series (sorted):\n",
      "1761     Abbeville\n",
      "17809     Aberdeen\n",
      "2297      Aberdeen\n",
      "9404      Aberdeen\n",
      "389       Aberdeen\n",
      "           ...    \n",
      "12441          NaN\n",
      "15767          NaN\n",
      "15812          NaN\n",
      "16054          NaN\n",
      "16608          NaN\n",
      "Name: City, Length: 18241, dtype: object\n",
      "\n",
      "After creating a new 'Location' Series: \n",
      "                   City Colors Reported Shape Reported State             Time  \\\n",
      "0                Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00   \n",
      "1           Willingboro             NaN          OTHER    NJ  6/30/1930 20:00   \n",
      "2               Holyoke             NaN           OVAL    CO  2/15/1931 14:00   \n",
      "3               Abilene             NaN           DISK    KS   6/1/1931 13:00   \n",
      "4  New York Worlds Fair             NaN          LIGHT    NY  4/18/1933 19:00   \n",
      "\n",
      "                   Location  \n",
      "0                Ithaca, NY  \n",
      "1           Willingboro, NJ  \n",
      "2               Holyoke, CO  \n",
      "3               Abilene, KS  \n",
      "4  New York Worlds Fair, NY  \n",
      "\n",
      "Calculate summary statistics: \n",
      "           City Colors Reported Shape Reported  State              Time  \\\n",
      "count     18215            2882          15597  18241             18241   \n",
      "unique     6475              27             27     52             16145   \n",
      "top     Seattle             RED          LIGHT     CA  11/16/1999 19:00   \n",
      "freq        187             780           2803   2529                27   \n",
      "\n",
      "           Location  \n",
      "count         18215  \n",
      "unique         8028  \n",
      "top     Seattle, WA  \n",
      "freq            187  \n",
      "\n",
      "Column names of ufo dataframe:  Index(['City', 'Colors Reported', 'Shape Reported', 'State', 'Time',\n",
      "       'Location'],\n",
      "      dtype='object')\n",
      "\n",
      "Column names of ufo dataframe after renaming two column names:  Index(['City', 'Colors Reported', 'Shape_Reported', 'State', 'Time',\n",
      "       'Location'],\n",
      "      dtype='object')\n",
      "\n",
      "Column names of ufo dataframe after removing two columns (city, state):  Index(['Colors Reported', 'Shape_Reported', 'Time', 'Location'], dtype='object')\n",
      "\n",
      "ufo dataframe after deleting first two rows: \n",
      "  Colors Reported Shape_Reported             Time                  Location\n",
      "2             NaN           OVAL  2/15/1931 14:00               Holyoke, CO\n",
      "3             NaN           DISK   6/1/1931 13:00               Abilene, KS\n",
      "4             NaN          LIGHT  4/18/1933 19:00  New York Worlds Fair, NY\n",
      "5             NaN           DISK  9/15/1934 15:30           Valley City, ND\n",
      "6             NaN         CIRCLE   6/15/1935 0:00           Crater Lake, CA\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read a CSV file\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "\n",
    "print(\"Overview of UFO data reports: \")\n",
    "print(ufo.head())\n",
    "print()\n",
    "\n",
    "# Series\n",
    "print(\"City series (sorted):\")\n",
    "print(ufo.City.sort_values())\n",
    "print()\n",
    "\n",
    "# Create a new 'Location' Series\n",
    "\n",
    "ufo['Location'] = ufo.City + ', ' + ufo.State\n",
    "print(\"After creating a new 'Location' Series: \")\n",
    "print(ufo.head())\n",
    "print()\n",
    "\n",
    "# Calculate summary statistics\n",
    "print(\"Calculate summary statistics: \")\n",
    "print(ufo.describe())\n",
    "print()\n",
    "\n",
    "# Column names of ufo dataframe\n",
    "print(\"Column names of ufo dataframe: \", ufo.columns)\n",
    "print()\n",
    "\n",
    "# Rename two columns using the 'rename' method\n",
    "ufo = ufo.rename(columns={'ColorsReported':'Colors_Reported', 'Shape Reported':'Shape_Reported'})\n",
    "print(\"Column names of ufo dataframe after renaming two column names: \", ufo.columns)\n",
    "print()\n",
    "\n",
    "# Remove multiple columns at once\n",
    "ufo = ufo.drop(['City', 'State'], axis=1)\n",
    "print(\"Column names of ufo dataframe after removing two columns (city, state): \", ufo.columns)\n",
    "print()\n",
    "\n",
    "# Remove multiple rows at once (axis=0 refers to rows)\n",
    "ufo = ufo.drop([0, 1], axis=0)\n",
    "print(\"ufo dataframe after deleting first two rows: \")\n",
    "print(ufo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830d1cdb-d28b-46fd-a05d-aef7b9729ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe of top-rated IMDb movies: \n",
      "   star_rating                     title content_rating   genre  duration  \\\n",
      "0          9.3  The Shawshank Redemption              R   Crime       142   \n",
      "1          9.2             The Godfather              R   Crime       175   \n",
      "2          9.1    The Godfather: Part II              R   Crime       200   \n",
      "3          9.0           The Dark Knight          PG-13  Action       152   \n",
      "4          8.9              Pulp Fiction              R   Crime       154   \n",
      "\n",
      "                                         actors_list  \n",
      "0  [u'Tim Robbins', u'Morgan Freeman', u'Bob Gunt...  \n",
      "1    [u'Marlon Brando', u'Al Pacino', u'James Caan']  \n",
      "2  [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "3  [u'Christian Bale', u'Heath Ledger', u'Aaron E...  \n",
      "4  [u'John Travolta', u'Uma Thurman', u'Samuel L....  \n",
      "\n",
      "Different ways to filter rows of a pandas DataFrame by column value: \n",
      "Example: Filter rows to only show movies with a duration of at least 200 minutes\n",
      "1. Using a for loop\n",
      "0    False\n",
      "1    False\n",
      "2     True\n",
      "3    False\n",
      "4    False\n",
      "dtype: bool\n",
      "\n",
      "2. Broadcasting\n",
      "     star_rating                                          title  \\\n",
      "2            9.1                         The Godfather: Part II   \n",
      "7            8.9  The Lord of the Rings: The Return of the King   \n",
      "17           8.7                                  Seven Samurai   \n",
      "78           8.4                    Once Upon a Time in America   \n",
      "85           8.4                             Lawrence of Arabia   \n",
      "142          8.3              Lagaan: Once Upon a Time in India   \n",
      "157          8.2                             Gone with the Wind   \n",
      "204          8.1                                        Ben-Hur   \n",
      "445          7.9                           The Ten Commandments   \n",
      "476          7.8                                         Hamlet   \n",
      "630          7.7                                      Malcolm X   \n",
      "767          7.6                It's a Mad, Mad, Mad, Mad World   \n",
      "\n",
      "    content_rating      genre  duration  \\\n",
      "2                R      Crime       200   \n",
      "7            PG-13  Adventure       201   \n",
      "17         UNRATED      Drama       207   \n",
      "78               R      Crime       229   \n",
      "85              PG  Adventure       216   \n",
      "142             PG  Adventure       224   \n",
      "157              G      Drama       238   \n",
      "204              G  Adventure       212   \n",
      "445       APPROVED  Adventure       220   \n",
      "476          PG-13      Drama       242   \n",
      "630          PG-13  Biography       202   \n",
      "767       APPROVED     Action       205   \n",
      "\n",
      "                                           actors_list  \n",
      "2    [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "7    [u'Elijah Wood', u'Viggo Mortensen', u'Ian McK...  \n",
      "17   [u'Toshir\\xf4 Mifune', u'Takashi Shimura', u'K...  \n",
      "78   [u'Robert De Niro', u'James Woods', u'Elizabet...  \n",
      "85   [u\"Peter O'Toole\", u'Alec Guinness', u'Anthony...  \n",
      "142  [u'Aamir Khan', u'Gracy Singh', u'Rachel Shell...  \n",
      "157  [u'Clark Gable', u'Vivien Leigh', u'Thomas Mit...  \n",
      "204  [u'Charlton Heston', u'Jack Hawkins', u'Stephe...  \n",
      "445  [u'Charlton Heston', u'Yul Brynner', u'Anne Ba...  \n",
      "476  [u'Kenneth Branagh', u'Julie Christie', u'Dere...  \n",
      "630  [u'Denzel Washington', u'Angela Bassett', u'De...  \n",
      "767  [u'Spencer Tracy', u'Milton Berle', u'Ethel Me...  \n",
      "\n",
      "3. Using the loc method\n",
      "     star_rating                                          title  \\\n",
      "2            9.1                         The Godfather: Part II   \n",
      "7            8.9  The Lord of the Rings: The Return of the King   \n",
      "17           8.7                                  Seven Samurai   \n",
      "78           8.4                    Once Upon a Time in America   \n",
      "85           8.4                             Lawrence of Arabia   \n",
      "142          8.3              Lagaan: Once Upon a Time in India   \n",
      "157          8.2                             Gone with the Wind   \n",
      "204          8.1                                        Ben-Hur   \n",
      "445          7.9                           The Ten Commandments   \n",
      "476          7.8                                         Hamlet   \n",
      "630          7.7                                      Malcolm X   \n",
      "767          7.6                It's a Mad, Mad, Mad, Mad World   \n",
      "\n",
      "    content_rating      genre  duration  \\\n",
      "2                R      Crime       200   \n",
      "7            PG-13  Adventure       201   \n",
      "17         UNRATED      Drama       207   \n",
      "78               R      Crime       229   \n",
      "85              PG  Adventure       216   \n",
      "142             PG  Adventure       224   \n",
      "157              G      Drama       238   \n",
      "204              G  Adventure       212   \n",
      "445       APPROVED  Adventure       220   \n",
      "476          PG-13      Drama       242   \n",
      "630          PG-13  Biography       202   \n",
      "767       APPROVED     Action       205   \n",
      "\n",
      "                                           actors_list  \n",
      "2    [u'Al Pacino', u'Robert De Niro', u'Robert Duv...  \n",
      "7    [u'Elijah Wood', u'Viggo Mortensen', u'Ian McK...  \n",
      "17   [u'Toshir\\xf4 Mifune', u'Takashi Shimura', u'K...  \n",
      "78   [u'Robert De Niro', u'James Woods', u'Elizabet...  \n",
      "85   [u\"Peter O'Toole\", u'Alec Guinness', u'Anthony...  \n",
      "142  [u'Aamir Khan', u'Gracy Singh', u'Rachel Shell...  \n",
      "157  [u'Clark Gable', u'Vivien Leigh', u'Thomas Mit...  \n",
      "204  [u'Charlton Heston', u'Jack Hawkins', u'Stephe...  \n",
      "445  [u'Charlton Heston', u'Yul Brynner', u'Anne Ba...  \n",
      "476  [u'Kenneth Branagh', u'Julie Christie', u'Dere...  \n",
      "630  [u'Denzel Washington', u'Angela Bassett', u'De...  \n",
      "767  [u'Spencer Tracy', u'Milton Berle', u'Ethel Me...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read a dataset of top-rated IMDb movies into a DataFrame\n",
    "movies = pd.read_csv('http://bit.ly/imdbratings')\n",
    "\n",
    "print(\"Dataframe of top-rated IMDb movies: \")\n",
    "print(movies.head())\n",
    "print()\n",
    "\n",
    "print(\"Different ways to filter rows of a pandas DataFrame by column value: \")\n",
    "print(\"Example: Filter rows to only show movies with a duration of at least 200 minutes\")\n",
    "\n",
    "print(\"1. Using a for loop\")\n",
    "# Create a list in which each element refers to a DataFrame row: True if the row satisfies the condition, False otherwise\n",
    "booleans = []\n",
    "for length in movies.duration:\n",
    "    if length >= 200:\n",
    "        booleans.append(True)\n",
    "    else:\n",
    "        booleans.append(False)\n",
    "is_long = pd.Series(booleans)\n",
    "print(is_long.head())\n",
    "print()\n",
    "\n",
    "print(\"2. Broadcasting\")\n",
    "print(movies[movies.duration >= 200])\n",
    "print()\n",
    "\n",
    "print(\"3. Using the loc method\")\n",
    "print(movies.loc[movies.duration >= 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1605ed05-1b89-40ea-ba50-712fcb2d1c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_7645/938015744.py:21: SyntaxWarning: invalid escape sequence '\\['\n",
      "  print(orders.choice_description.str.replace('[\\[\\]]', '').head())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: \n",
      "   order_id  quantity                              item_name  \\\n",
      "0         1         1           Chips and Fresh Tomato Salsa   \n",
      "1         1         1                                   Izze   \n",
      "2         1         1                       Nantucket Nectar   \n",
      "3         1         1  Chips and Tomatillo-Green Chili Salsa   \n",
      "4         2         2                           Chicken Bowl   \n",
      "\n",
      "                                  choice_description item_price  \n",
      "0                                                NaN     $2.39   \n",
      "1                                       [Clementine]     $3.39   \n",
      "2                                            [Apple]     $3.39   \n",
      "3                                                NaN     $2.39   \n",
      "4  [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n",
      "\n",
      "String methods in pandas: \n",
      "'item_name' series (in uppercase): \n",
      "0             CHIPS AND FRESH TOMATO SALSA\n",
      "1                                     IZZE\n",
      "2                         NANTUCKET NECTAR\n",
      "3    CHIPS AND TOMATILLO-GREEN CHILI SALSA\n",
      "4                             CHICKEN BOWL\n",
      "Name: item_name, dtype: object\n",
      "\n",
      "Checks for a substring 'Chicken' in the given dataframe: \n",
      "    order_id  quantity             item_name  \\\n",
      "4          2         2          Chicken Bowl   \n",
      "5          3         1          Chicken Bowl   \n",
      "11         6         1  Chicken Crispy Tacos   \n",
      "12         6         1    Chicken Soft Tacos   \n",
      "13         7         1          Chicken Bowl   \n",
      "\n",
      "                                   choice_description item_price  \n",
      "4   [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98   \n",
      "5   [Fresh Tomato Salsa (Mild), [Rice, Cheese, Sou...    $10.98   \n",
      "11  [Roasted Chili Corn Salsa, [Fajita Vegetables,...     $8.75   \n",
      "12  [Roasted Chili Corn Salsa, [Rice, Black Beans,...     $8.75   \n",
      "13  [Fresh Tomato Salsa, [Fajita Vegetables, Rice,...    $11.25   \n",
      "\n",
      "0                                                  NaN\n",
      "1                                         [Clementine]\n",
      "2                                              [Apple]\n",
      "3                                                  NaN\n",
      "4    [Tomatillo-Red Chili Salsa (Hot), [Black Beans...\n",
      "Name: choice_description, dtype: object\n",
      "\n",
      "Examine the data type of each Series: \n",
      "order_id               int64\n",
      "quantity               int64\n",
      "item_name             object\n",
      "choice_description    object\n",
      "item_price            object\n",
      "dtype: object\n",
      "\n",
      "Dataframe after replacing '$' and converting string to float of 'item_price' series: \n",
      "0     2.39\n",
      "1     3.39\n",
      "2     3.39\n",
      "3     2.39\n",
      "4    16.98\n",
      "Name: item_price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read a dataset of Chipotle orders into a DataFrame\n",
    "orders = pd.read_table('http://bit.ly/chiporders')\n",
    "\n",
    "print(\"Dataframe: \")\n",
    "print(orders.head())\n",
    "print()\n",
    "\n",
    "print(\"String methods in pandas: \")\n",
    "\n",
    "print(\"'item_name' series (in uppercase): \")\n",
    "print(orders.item_name.str.upper().head())\n",
    "print()\n",
    "\n",
    "print(\"Checks for a substring 'Chicken' in the given dataframe: \")\n",
    "print(orders[orders.item_name.str.contains('Chicken')].head())\n",
    "print()\n",
    "\n",
    "# Many pandas string methods support regular expressions (regex)\n",
    "print(orders.choice_description.str.replace('[\\[\\]]', '').head())\n",
    "print()\n",
    "\n",
    "print(\"Examine the data type of each Series: \")\n",
    "print(orders.dtypes)\n",
    "print()\n",
    "\n",
    "print(\"Dataframe after replacing '$' and converting string to float of 'item_price' series: \")\n",
    "print(orders.item_price.str.replace('$', '').astype(float).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3045fff-a812-483b-a018-ebd15fe57e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: \n",
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n",
      "2                           0.7    Africa  \n",
      "3                          12.4    Europe  \n",
      "4                           5.9    Africa  \n",
      "\n",
      "Mean beer servings across the entire dataset: 106.16062176165804\n",
      "Mean beer servings just for countries in Africa: 61.471698113207545\n",
      "\n",
      "Aggregate functions used with groupby: \n",
      "\n",
      "Mean beer servings for each continent: continent\n",
      "Africa            61.471698\n",
      "Asia              37.045455\n",
      "Europe           193.777778\n",
      "North America    145.434783\n",
      "Oceania           89.687500\n",
      "South America    175.083333\n",
      "Name: beer_servings, dtype: float64\n",
      "Maximum beer servings for each continent: continent\n",
      "Africa           376\n",
      "Asia             247\n",
      "Europe           361\n",
      "North America    285\n",
      "Oceania          306\n",
      "South America    333\n",
      "Name: beer_servings, dtype: int64\n",
      "\n",
      "Multiple aggregation functions can be applied simultaneously: \n",
      "               count        mean  min  max\n",
      "continent                                 \n",
      "Africa            53   61.471698    0  376\n",
      "Asia              44   37.045455    0  247\n",
      "Europe            45  193.777778    0  361\n",
      "North America     23  145.434783    1  285\n",
      "Oceania           16   89.687500    0  306\n",
      "South America     12  175.083333   93  333\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/groupby/ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[0;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[1;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[1;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/groupby/ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[0;34m(self, obj, func)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[0;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[1;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[1;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2456\u001b[0m     )\n\u001b[1;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6548\u001b[0m ):\n\u001b[0;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[1;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  12422\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[1;32m  12379\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1701\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string 'AlgeriaAngolaBeninBotswanaBurkina FasoBurundiCote d'IvoireCabo VerdeCameroonCentral African RepublicChadComorosCongoDR CongoDjiboutiEgyptEquatorial GuineaEritreaEthiopiaGabonGambiaGhanaGuineaGuinea-BissauKenyaLesothoLiberiaLibyaMadagascarMalawiMaliMauritaniaMauritiusMoroccoMozambiqueNamibiaNigerNigeriaRwandaSao Tome & PrincipeSenegalSeychellesSierra LeoneSomaliaSouth AfricaSudanSwazilandTogoTunisiaUgandaTanzaniaZambiaZimbabwe' to numeric",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(drinks\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinent\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mbeer_servings\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Specifying a column to which the aggregation function should be applied is not required\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(drinks\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontinent\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[0;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   2446\u001b[0m         grouped_mean,\n\u001b[1;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[1;32m   2448\u001b[0m         engine_kwargs,\n\u001b[1;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2450\u001b[0m     )\n\u001b[1;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[1;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   2456\u001b[0m     )\n\u001b[1;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[1;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/internals/managers.py:1469\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[1;32m   1466\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[1;32m   1467\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[1;32m   1468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[0;32m-> 1469\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[1;32m   1470\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/internals/blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[0;34m(self, func, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Downloads/yes/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[0;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[1;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[0;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read a dataset of alcohol consumption into a DataFrame\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "\n",
    "print(\"Dataframe: \")\n",
    "print(drinks.head())\n",
    "print()\n",
    "\n",
    "print(\"Mean beer servings across the entire dataset:\", drinks.beer_servings.mean())\n",
    "print(\"Mean beer servings just for countries in Africa:\", drinks[drinks.continent == 'Africa'].beer_servings.mean())\n",
    "print()\n",
    "\n",
    "print(\"Aggregate functions used with groupby: \")\n",
    "print()\n",
    "\n",
    "print(\"Mean beer servings for each continent:\", drinks.groupby('continent').beer_servings.mean())\n",
    "print(\"Maximum beer servings for each continent:\", drinks.groupby('continent').beer_servings.max())\n",
    "print()\n",
    "\n",
    "print(\"Multiple aggregation functions can be applied simultaneously: \")\n",
    "print(drinks.groupby('continent').beer_servings.agg(['count', 'mean', 'min', 'max']))\n",
    "\n",
    "# Specifying a column to which the aggregation function should be applied is not required\n",
    "print(drinks.groupby('continent').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48195a3c-5c7c-44f9-91f8-86f4f1616637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        City  Colors Reported  Shape Reported  State   Time\n",
      "18236  False             True           False  False  False\n",
      "18237  False             True           False  False  False\n",
      "18238  False             True            True  False  False\n",
      "18239  False            False           False  False  False\n",
      "18240  False             True           False  False  False\n",
      "       City  Colors Reported  Shape Reported  State  Time\n",
      "18236  True            False            True   True  True\n",
      "18237  True            False            True   True  True\n",
      "18238  True            False           False   True  True\n",
      "18239  True             True            True   True  True\n",
      "18240  True            False            True   True  True\n",
      "City                  26\n",
      "Colors Reported    15359\n",
      "Shape Reported      2644\n",
      "State                  0\n",
      "Time                   0\n",
      "dtype: int64\n",
      "(18241, 5)\n",
      "(18241, 5)\n",
      "(15575, 5)\n",
      "Shape Reported\n",
      "LIGHT       2803\n",
      "DISK        2122\n",
      "TRIANGLE    1889\n",
      "OTHER       1402\n",
      "CIRCLE      1365\n",
      "Name: count, dtype: int64\n",
      "Shape Reported\n",
      "VARIOUS     2977\n",
      "LIGHT       2803\n",
      "DISK        2122\n",
      "TRIANGLE    1889\n",
      "OTHER       1402\n",
      "Name: count, dtype: int64\n",
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "0  Afghanistan              0                0              0   \n",
      "1      Albania             89              132             54   \n",
      "2      Algeria             25                0             14   \n",
      "3      Andorra            245              138            312   \n",
      "4       Angola            217               57             45   \n",
      "\n",
      "   total_litres_of_pure_alcohol continent  \n",
      "0                           0.0      Asia  \n",
      "1                           4.9    Europe  \n",
      "2                           0.7    Africa  \n",
      "3                          12.4    Europe  \n",
      "4                           5.9    Africa  \n",
      "RangeIndex(start=0, stop=193, step=1)\n",
      "   0   1  2           3      4\n",
      "0  1  24  M  technician  85711\n",
      "1  2  53  F       other  94043\n",
      "2  3  23  M      writer  32067\n",
      "3  4  24  M  technician  43537\n",
      "4  5  33  F       other  15213\n",
      "       country  beer_servings  spirit_servings  wine_servings  \\\n",
      "6    Argentina            193               25            221   \n",
      "20     Bolivia            167               41              8   \n",
      "23      Brazil            245              145             16   \n",
      "35       Chile            130              124            172   \n",
      "37    Colombia            159               76              3   \n",
      "52     Ecuador            162               74              3   \n",
      "72      Guyana             93              302              1   \n",
      "132   Paraguay            213              117             74   \n",
      "133       Peru            163              160             21   \n",
      "163   Suriname            128              178              7   \n",
      "185    Uruguay            115               35            220   \n",
      "188  Venezuela            333              100              3   \n",
      "\n",
      "     total_litres_of_pure_alcohol      continent  \n",
      "6                             8.3  South America  \n",
      "20                            3.8  South America  \n",
      "23                            7.2  South America  \n",
      "35                            7.6  South America  \n",
      "37                            4.2  South America  \n",
      "52                            4.2  South America  \n",
      "72                            7.1  South America  \n",
      "132                           7.3  South America  \n",
      "133                           6.1  South America  \n",
      "163                           5.6  South America  \n",
      "185                           6.6  South America  \n",
      "188                           7.7  South America  \n",
      "245\n",
      "             beer_servings  spirit_servings  wine_servings  \\\n",
      "country                                                      \n",
      "Afghanistan              0                0              0   \n",
      "Albania                 89              132             54   \n",
      "Algeria                 25                0             14   \n",
      "Andorra                245              138            312   \n",
      "Angola                 217               57             45   \n",
      "\n",
      "             total_litres_of_pure_alcohol continent  \n",
      "country                                              \n",
      "Afghanistan                           0.0      Asia  \n",
      "Albania                               4.9    Europe  \n",
      "Algeria                               0.7    Africa  \n",
      "Andorra                              12.4    Europe  \n",
      "Angola                                5.9    Africa  \n",
      "20.0\n",
      "Index(['Africa', 'Europe', 'Asia', 'North America', 'Oceania',\n",
      "       'South America'],\n",
      "      dtype='object', name='continent')\n",
      "[53 45 44 23 16 12]\n",
      "continent\n",
      "South America    12\n",
      "Oceania          16\n",
      "North America    23\n",
      "Asia             44\n",
      "Europe           45\n",
      "Africa           53\n",
      "Name: count, dtype: int64\n",
      "             beer_servings  spirit_servings  wine_servings  \\\n",
      "Afghanistan              0                0              0   \n",
      "Albania                 89              132             54   \n",
      "Algeria                 25                0             14   \n",
      "Andorra                245              138            312   \n",
      "Angola                 217               57             45   \n",
      "\n",
      "             total_litres_of_pure_alcohol continent  population  \n",
      "Afghanistan                           0.0      Asia         NaN  \n",
      "Albania                               4.9    Europe   3000000.0  \n",
      "Algeria                               0.7    Africa         NaN  \n",
      "Andorra                              12.4    Europe     85000.0  \n",
      "Angola                                5.9    Africa         NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# UFO Sightings Dataset\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "\n",
    "# Check for null values\n",
    "print(ufo.isnull().tail())\n",
    "print(ufo.notnull().tail())\n",
    "\n",
    "# Count of null values in each column\n",
    "print(ufo.isnull().sum())\n",
    "\n",
    "# Shape of the dataset\n",
    "print(ufo.shape)\n",
    "\n",
    "# Drop rows where all values are missing\n",
    "print(ufo.dropna(how='all').shape)\n",
    "\n",
    "# Drop rows where there are missing values in the 'City' or 'Shape Reported' columns\n",
    "print(ufo.dropna(subset=['City', 'Shape Reported'], how='any').shape)\n",
    "\n",
    "# Top 5 most common values in the 'Shape Reported' column\n",
    "print(ufo['Shape Reported'].value_counts().head())\n",
    "\n",
    "# Fill in missing values with a specified value\n",
    "ufo['Shape Reported'] = ufo['Shape Reported'].fillna(value='VARIOUS')\n",
    "\n",
    "# Confirm that the missing values were filled in\n",
    "print(ufo['Shape Reported'].value_counts().head())\n",
    "\n",
    "# Drinks Consumption by Country Dataset\n",
    "drinks = pd.read_csv('http://bit.ly/drinksbycountry')\n",
    "\n",
    "# First few rows of the dataset\n",
    "print(drinks.head())\n",
    "\n",
    "# Index of the dataset\n",
    "print(drinks.index)\n",
    "\n",
    "# Read in a table with a custom separator and no header row\n",
    "print(pd.read_table('http://bit.ly/movieusers', header=None, sep='|').head())\n",
    "\n",
    "# Filter the dataset to show only rows where the continent is 'South America'\n",
    "print(drinks[drinks.continent == 'South America'])\n",
    "\n",
    "# Select a specific value from the dataset using the index and column labels\n",
    "print(drinks.loc[23, 'beer_servings'])\n",
    "\n",
    "# Set the 'country' column as the index of the dataset\n",
    "drinks.set_index('country', inplace=True)\n",
    "\n",
    "# First few rows of the dataset with the new index\n",
    "print(drinks.head())\n",
    "\n",
    "# Interact with the dataset using its index and columns\n",
    "print(drinks.describe().loc['25%', 'beer_servings'])\n",
    "\n",
    "# Access the Series index\n",
    "print(drinks.continent.value_counts().index)\n",
    "\n",
    "# Access the Series values\n",
    "print(drinks.continent.value_counts().values)\n",
    "\n",
    "# Sort a Series by its values\n",
    "print(drinks.continent.value_counts().sort_values())\n",
    "\n",
    "# Create a new Series with population data\n",
    "people = pd.Series([3000000, 85000], index=['Albania', 'Andorra'], name='population')\n",
    "\n",
    "# Concatenate the 'drinks' DataFrame with the 'population' Series\n",
    "print(pd.concat([drinks, people], axis=1).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4027eb6a-6d1f-4e29-ba7c-de94c4b83603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe: \n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "\n",
      "Selecting multiple rows and columns from a pandas Data Frame using 'loc': \n",
      "\n",
      "First row, all columns: \n",
      "City                       Ithaca\n",
      "Colors Reported               NaN\n",
      "Shape Reported           TRIANGLE\n",
      "State                          NY\n",
      "Time               6/1/1930 22:00\n",
      "Name: 0, dtype: object\n",
      "\n",
      "First 3 rows, all columns: \n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "\n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "\n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "2      Holyoke             NaN           OVAL    CO  2/15/1931 14:00\n",
      "\n",
      "First 3 rows, only one column 'City': \n",
      "0         Ithaca\n",
      "1    Willingboro\n",
      "2        Holyoke\n",
      "Name: City, dtype: object\n",
      "\n",
      "First 3 rows, two columns 'City' and 'State': \n",
      "          City State\n",
      "0       Ithaca    NY\n",
      "1  Willingboro    NJ\n",
      "2      Holyoke    CO\n",
      "\n",
      "Accomplish the same thing using double brackets: \n",
      "          City State\n",
      "0       Ithaca    NY\n",
      "1  Willingboro    NJ\n",
      "2      Holyoke    CO\n",
      "\n",
      "First 3 rows, columns 'City' through 'State': \n",
      "          City Colors Reported Shape Reported State\n",
      "0       Ithaca             NaN       TRIANGLE    NY\n",
      "1  Willingboro             NaN          OTHER    NJ\n",
      "2      Holyoke             NaN           OVAL    CO\n",
      "\n",
      "Accomplish the same thing using 'head' and 'drop': \n",
      "          City Colors Reported Shape Reported State\n",
      "0       Ithaca             NaN       TRIANGLE    NY\n",
      "1  Willingboro             NaN          OTHER    NJ\n",
      "2      Holyoke             NaN           OVAL    CO\n",
      "\n",
      "Rows in which the 'City' is 'Oakland', column 'State': \n",
      "1694     CA\n",
      "2144     CA\n",
      "4686     MD\n",
      "7293     CA\n",
      "8488     CA\n",
      "8768     CA\n",
      "10816    OR\n",
      "10948    CA\n",
      "11045    CA\n",
      "12322    CA\n",
      "12941    CA\n",
      "16803    MD\n",
      "17322    CA\n",
      "Name: State, dtype: object\n",
      "\n",
      "Accomplish the same thing using 'chained indexing': \n",
      "1694     CA\n",
      "2144     CA\n",
      "4686     MD\n",
      "7293     CA\n",
      "8488     CA\n",
      "8768     CA\n",
      "10816    OR\n",
      "10948    CA\n",
      "11045    CA\n",
      "12322    CA\n",
      "12941    CA\n",
      "16803    MD\n",
      "17322    CA\n",
      "Name: State, dtype: object\n",
      "\n",
      "Selecting multiple rows and columns from a pandas DataFrame using 'iloc': \n",
      "\n",
      "Rows in positions 0 and 1, columns in positions 0 and 3: \n",
      "          City State\n",
      "0       Ithaca    NY\n",
      "1  Willingboro    NJ\n",
      "\n",
      "Rows in positions 0 through 2 (exclusive), columns in positions 0 through 4 (exclusive): \n",
      "          City Colors Reported Shape Reported State\n",
      "0       Ithaca             NaN       TRIANGLE    NY\n",
      "1  Willingboro             NaN          OTHER    NJ\n",
      "\n",
      "Rows in positions 0 through 2 (exclusive), all columns: \n",
      "          City Colors Reported Shape Reported State             Time\n",
      "0       Ithaca             NaN       TRIANGLE    NY   6/1/1930 22:00\n",
      "1  Willingboro             NaN          OTHER    NJ  6/30/1930 20:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read a CSV file\n",
    "ufo = pd.read_csv('http://bit.ly/uforeports')\n",
    "\n",
    "print(\"Dataframe: \")\n",
    "print(ufo.head(3))\n",
    "print()\n",
    "\n",
    "print(\"Selecting multiple rows and columns from a pandas Data Frame using 'loc': \")\n",
    "print()\n",
    "\n",
    "# loc method is used to select rows and columns by label\n",
    "print(\"First row, all columns: \")\n",
    "print(ufo.loc[0, :])\n",
    "print()\n",
    "\n",
    "print(\"First 3 rows, all columns: \")\n",
    "print(ufo.loc[[0, 1, 2], :])\n",
    "print()\n",
    "\n",
    "# rows 0 through 2 (inclusive), all columns\n",
    "print(ufo.loc[0:2, :])\n",
    "print()\n",
    "\n",
    "# this implies \"all columns\", but explicitly stating \"all columns\" is better\n",
    "print(ufo.loc[0:2, :])\n",
    "print()\n",
    "\n",
    "print(\"First 3 rows, only one column 'City': \")\n",
    "print(ufo.loc[0:2, 'City'])\n",
    "print()\n",
    "\n",
    "print(\"First 3 rows, two columns 'City' and 'State': \")\n",
    "print(ufo.loc[0:2, ['City', 'State']])\n",
    "print()\n",
    "\n",
    "print(\"Accomplish the same thing using double brackets: \")\n",
    "# using 'loc' is preferred since it's more explicit\n",
    "print(ufo[['City', 'State']].head(3))\n",
    "print()\n",
    "\n",
    "print(\"First 3 rows, columns 'City' through 'State': \")\n",
    "print(ufo.loc[0:2, 'City':'State'])\n",
    "print()\n",
    "\n",
    "print(\"Accomplish the same thing using 'head' and 'drop': \")\n",
    "print(ufo.head(3).drop('Time', axis=1))\n",
    "print()\n",
    "\n",
    "print(\"Rows in which the 'City' is 'Oakland', column 'State': \")\n",
    "print(ufo.loc[ufo.City == 'Oakland', 'State'])\n",
    "print()\n",
    "\n",
    "print(\"Accomplish the same thing using 'chained indexing': \")\n",
    "# using 'loc' is preferred since chained indexing can cause problems\n",
    "print(ufo[ufo.City == 'Oakland'].State)\n",
    "print()\n",
    "\n",
    "print(\"Selecting multiple rows and columns from a pandas DataFrame using 'iloc': \")\n",
    "print()\n",
    "\n",
    "print(\"Rows in positions 0 and 1, columns in positions 0 and 3: \")\n",
    "print(ufo.iloc[[0, 1], [0, 3]])\n",
    "print()\n",
    "\n",
    "print(\"Rows in positions 0 through 2 (exclusive), columns in positions 0 through 4 (exclusive): \")\n",
    "print(ufo.iloc[0:2, 0:4])\n",
    "print()\n",
    "\n",
    "print(\"Rows in positions 0 through 2 (exclusive), all columns: \")\n",
    "print(ufo.iloc[0:2, :])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04a856a3-05e4-4965-b315-4dd9aaa140e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dummy variables in pandas: \n",
      "\n",
      "Dataframe: \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "   female   male\n",
      "0   False   True\n",
      "1    True  False\n",
      "2    True  False\n",
      "3    True  False\n",
      "4   False   True\n",
      "\n",
      "    male\n",
      "0   True\n",
      "1  False\n",
      "2  False\n",
      "3  False\n",
      "4   True\n",
      "\n",
      "   Sex_male\n",
      "0      True\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4      True\n",
      "\n",
      "   Embarked_C  Embarked_Q  Embarked_S\n",
      "0       False       False        True\n",
      "1        True       False       False\n",
      "2       False       False        True\n",
      "3       False       False        True\n",
      "4       False       False        True\n",
      "5       False        True       False\n",
      "6       False       False        True\n",
      "7       False       False        True\n",
      "8       False       False        True\n",
      "9        True       False       False\n",
      "\n",
      "   Embarked_Q  Embarked_S\n",
      "0       False        True\n",
      "1       False       False\n",
      "2       False        True\n",
      "3       False        True\n",
      "4       False        True\n",
      "5        True       False\n",
      "6       False        True\n",
      "7       False        True\n",
      "8       False        True\n",
      "9       False       False\n",
      "\n",
      "Dataframe: \n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin  Sex_female  Sex_male  Embarked_C  \\\n",
      "0         A/5 21171   7.2500   NaN       False      True       False   \n",
      "1          PC 17599  71.2833   C85        True     False        True   \n",
      "2  STON/O2. 3101282   7.9250   NaN        True     False       False   \n",
      "3            113803  53.1000  C123        True     False       False   \n",
      "4            373450   8.0500   NaN       False      True       False   \n",
      "\n",
      "   Embarked_Q  Embarked_S  \n",
      "0       False        True  \n",
      "1       False       False  \n",
      "2       False        True  \n",
      "3       False        True  \n",
      "4       False        True  \n",
      "\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin  Sex_male  Embarked_Q  Embarked_S  \n",
      "0         A/5 21171   7.2500   NaN      True       False        True  \n",
      "1          PC 17599  71.2833   C85     False       False       False  \n",
      "2  STON/O2. 3101282   7.9250   NaN     False       False        True  \n",
      "3            113803  53.1000  C123     False       False        True  \n",
      "4            373450   8.0500   NaN      True       False        True  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Creating dummy variables in pandas: \")\n",
    "print()\n",
    "\n",
    "# Read the training dataset from Kaggle's Titanic competition\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "\n",
    "print(\"Dataframe: \")\n",
    "print(train.head())\n",
    "print()\n",
    "\n",
    "# Use 'get_dummies' to create one column for every possible value\n",
    "print(pd.get_dummies(train['Sex']).head())\n",
    "print()\n",
    "\n",
    "# Drop the first dummy variable ('female') using the 'iloc' method\n",
    "print(pd.get_dummies(train['Sex']).iloc[:, 1:].head())\n",
    "print()\n",
    "\n",
    "# Add a prefix to identify the source of the dummy variables\n",
    "print(pd.get_dummies(train['Sex'], prefix='Sex').iloc[:, 1:].head())\n",
    "print()\n",
    "\n",
    "# Use 'get_dummies' with a feature that has 3 possible values\n",
    "print(pd.get_dummies(train['Embarked'], prefix='Embarked').head(10))\n",
    "print()\n",
    "\n",
    "# Drop the first dummy variable ('C')\n",
    "print(pd.get_dummies(train['Embarked'], prefix='Embarked').iloc[:, 1:].head(10))\n",
    "print()\n",
    "\n",
    "# Reset the DataFrame\n",
    "train = pd.read_csv('http://bit.ly/kaggletrain')\n",
    "\n",
    "print(\"Dataframe: \")\n",
    "print(train.head())\n",
    "print()\n",
    "\n",
    "# Pass the DataFrame to 'get_dummies' and specify which columns to dummy (it drops the original columns)\n",
    "print(pd.get_dummies(train, columns=['Sex', 'Embarked']).head())\n",
    "print()\n",
    "\n",
    "# Use the 'drop_first' parameter (new in pandas 0.18) to drop the first dummy variable for each feature\n",
    "print(pd.get_dummies(train, columns=['Sex', 'Embarked'], drop_first=True).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906b2ba-2188-4eb6-83ed-0314911c51eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
